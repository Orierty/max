"""
–§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π Qwen2-VL
"""
import os
import logging
import requests

from bot.config import VISION_MODEL_ENABLED, MODELS_DIR

logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
vision_model = None
vision_processor = None

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º AI –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ–π—Ä–æ–Ω–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞
if VISION_MODEL_ENABLED:
    try:
        import torch
        from PIL import Image
        from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
        from qwen_vl_utils import process_vision_info
        logger.info("AI –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    except ImportError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ AI –±–∏–±–ª–∏–æ—Ç–µ–∫: {e}")
        logger.error("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install torch transformers pillow qwen-vl-utils")
else:
    logger.info("Vision Model –æ—Ç–∫–ª—é—á–µ–Ω–∞ (VISION_MODEL_ENABLED=false), AI –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è")

def init_vision_model():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å Qwen2-VL –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    global vision_model, vision_processor

    try:
        # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—è–º–∏ –≤ —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        models_dir = os.path.join(os.path.dirname(__file__), "..", "..", MODELS_DIR)
        os.makedirs(models_dir, exist_ok=True)

        # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPTQ –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω auto-gptq
        try:
            import auto_gptq
            model_name = "Qwen/Qwen2-VL-2B-Instruct-GPTQ-Int4"
            local_model_path = os.path.join(models_dir, "Qwen2-VL-2B-Instruct-GPTQ-Int4")
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ GPTQ –º–æ–¥–µ–ª–∏ Qwen2-VL-2B-Instruct-GPTQ-Int4...")
        except ImportError:
            # –ï—Å–ª–∏ auto-gptq –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—É—é –º–æ–¥–µ–ª—å
            model_name = "Qwen/Qwen2-VL-2B-Instruct"
            local_model_path = os.path.join(models_dir, "Qwen2-VL-2B-Instruct")
            logger.info("auto-gptq –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å Qwen2-VL-2B-Instruct...")
            logger.warning("–î–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å: pip install auto-gptq")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
        if os.path.exists(local_model_path) and os.path.isdir(local_model_path):
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ {local_model_path}")
            model_source = local_model_path
        else:
            logger.info(f"–ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–∫–∞—á–∞–Ω–∞ –∏–∑ HuggingFace –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {local_model_path}")
            model_source = model_name

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        vision_processor = AutoProcessor.from_pretrained(
            model_source,
            trust_remote_code=True,
            cache_dir=models_dir if model_source == model_name else None
        )

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º float16 –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ GPU, –∏–Ω–∞—á–µ float32 –¥–ª—è CPU
        dtype = torch.float16 if torch.cuda.is_available() else torch.float32

        vision_model = Qwen2VLForConditionalGeneration.from_pretrained(
            model_source,
            torch_dtype=dtype,
            device_map="auto",
            trust_remote_code=True,
            cache_dir=models_dir if model_source == model_name else None
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –æ–Ω–∞ –±—ã–ª–∞ —Å–∫–∞—á–∞–Ω–∞ –∏–∑ HuggingFace
        if model_source == model_name:
            logger.info(f"–°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ –≤ {local_model_path}...")
            vision_model.save_pretrained(local_model_path)
            vision_processor.save_pretrained(local_model_path)
            logger.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ")

        device = next(vision_model.parameters()).device
        logger.info(f"–ú–æ–¥–µ–ª—å Qwen2-VL —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        return True

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ Qwen2-VL: {e}", exc_info=True)
        return False

def describe_image(image_path):
    """–û–ø–∏—Å—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —Å –ø–æ–º–æ—â—å—é Qwen2-VL"""
    global vision_model, vision_processor

    # –ï—Å–ª–∏ –Ω–µ–π—Ä–æ–Ω–∫–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
    if not VISION_MODEL_ENABLED:
        logger.info("Vision Model –æ—Ç–∫–ª—é—á–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É")
        return ("üîß –†–µ–∂–∏–º –∑–∞–≥–ª—É—à–∫–∏ (Vision Model –æ—Ç–∫–ª—é—á–µ–Ω–∞)\n\n"
                "–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –≤–∏–¥–Ω–æ: [–∑–¥–µ—Å—å –±—ã–ª–æ –±—ã –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç –Ω–µ–π—Ä–æ–Ω–∫–∏]\n\n"
                "–î–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ VISION_MODEL_ENABLED=true –≤ —Ñ–∞–π–ª–µ .env")

    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –∑–∞–≥—Ä—É–∂–∞–µ–º –µ—ë
    if vision_model is None or vision_processor is None:
        logger.info("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º...")
        if not init_vision_model():
            return "–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."

    try:
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = Image.open(image_path).convert('RGB')

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "image": image_path,
                    },
                    {
                        "type": "text",
                        "text": "–û–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–æ —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ —ç—Ç–æ–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–µ—Ç–∞–ª—å–Ω—ã–º –∏ —Ç–æ—á–Ω—ã–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏."
                    },
                ],
            }
        ]

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
        text = vision_processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_inputs, video_inputs = process_vision_info(messages)

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        inputs = vision_processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt",
        )

        device = next(vision_model.parameters()).device
        inputs = inputs.to(device)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
        with torch.no_grad():
            generated_ids = vision_model.generate(
                **inputs,
                max_new_tokens=512,
                temperature=0.7,
                do_sample=True
            )

        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        generated_ids_trimmed = [
            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        output_text = vision_processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]

        logger.info("–û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ")
        return output_text

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"

def download_image(url, save_path):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ URL"""
    try:
        response = requests.get(url, timeout=30)
        if response.status_code == 200:
            with open(save_path, 'wb') as f:
                f.write(response.content)
            logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {save_path}")
            return True
        else:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return False
